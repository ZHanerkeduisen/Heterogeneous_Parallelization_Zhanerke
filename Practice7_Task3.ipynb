{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbV5MHmBsULk",
        "outputId": "05ac0675-dba9-4023-87f8-9363900fa37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting practice73.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile practice73.cu\n",
        "\n",
        "// Practice 7 Task 3\n",
        "// 1. Замерьте время выполнения редукции и сканирования для массивов разного размера.\n",
        "// 2. Сравните производительность с CPU-реализацией.\n",
        "// 3. Проведите оптимизацию кода, используя различные типы памяти CUDA.\n",
        "\n",
        "#include <iostream>               // Для стандартного ввода-вывода\n",
        "#include <cuda_runtime.h>         // Для CUDA Runtime API\n",
        "#include <chrono>                 // Для измерения времени\n",
        "\n",
        "using namespace std;              // Чтобы не писать std::\n",
        "\n",
        "// CUDA KERNEL: ПАРАЛЛЕЛЬНАЯ РЕДУКЦИЯ\n",
        "__global__ void reductionKernel(int *d_input, int *d_output, int n) {\n",
        "    extern __shared__ int sdata[];            // Объявляем shared memory для блока потоков (быстрая память на блок)\n",
        "    int tid = threadIdx.x;                    // Локальный индекс потока в блоке (0..blockDim.x-1)\n",
        "    int i = blockIdx.x * blockDim.x + tid;    // Глобальный индекс потока в массиве данных\n",
        "\n",
        "    // Загружаем данные в shared memory\n",
        "    sdata[tid] = (i < n) ? d_input[i] : 0;    // Если индекс не выходит за пределы массива, копируем элемент, иначе ставим 0\n",
        "    __syncthreads();                          // Синхронизация всех потоков блока перед началом редукции\n",
        "\n",
        "    // Редукция в блоке: складываем элементы попарно\n",
        "    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) { // На каждом шаге уменьшаем количество активных потоков в 2 раза\n",
        "        if (tid < s) sdata[tid] += sdata[tid + s];          // Складываем пару элементов\n",
        "        __syncthreads();                                    // Синхронизация перед следующим шагом\n",
        "    }\n",
        "\n",
        "    // Записываем сумму блока в глобальную память\n",
        "    if (tid == 0) d_output[blockIdx.x] = sdata[0];\n",
        "}\n",
        "\n",
        "// CUDA KERNEL: ПРЕФИКСНАЯ СУММА\n",
        "__global__ void prefixSumKernel(int *d_input, int *d_output, int n) {\n",
        "    extern __shared__ int temp[];                // Shared memory для блока потоков\n",
        "    int tid = threadIdx.x;                       // Локальный индекс потока\n",
        "    int i = blockIdx.x * blockDim.x + tid;       // Глобальный индекс элемента массива\n",
        "\n",
        "    // Загружаем данные в shared memory\n",
        "    temp[tid] = (i < n) ? d_input[i] : 0;        // Если вышли за предел массива, кладем 0\n",
        "    __syncthreads();                             // Синхронизация потоков\n",
        "\n",
        "    // Шаг вверх (upsweep) — строим дерево сумм\n",
        "    for (int offset = 1; offset < blockDim.x; offset *= 2) {\n",
        "        int index = (tid + 1) * offset * 2 - 1;  // Вычисляем индекс для текущей пары\n",
        "        if (index < blockDim.x) temp[index] += temp[index - offset]; // Складываем элементы\n",
        "        __syncthreads();                        // Синхронизация перед следующим шагом\n",
        "    }\n",
        "\n",
        "    // Шаг вниз (downsweep) — вычисляем префиксные суммы\n",
        "    if (tid == 0) temp[blockDim.x - 1] = 0;      // Обнуляем последний элемент перед downsweep\n",
        "    __syncthreads();                             // Синхронизация потоков\n",
        "\n",
        "    for (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n",
        "        int index = (tid + 1) * offset * 2 - 1;  // Индекс текущей пары\n",
        "        if (index < blockDim.x) {\n",
        "            int t = temp[index - offset];        // Сохраняем значение для обмена\n",
        "            temp[index - offset] = temp[index];  // Меняем местами\n",
        "            temp[index] += t;                    // Складываем для префиксной суммы\n",
        "        }\n",
        "        __syncthreads();                        // Синхронизация перед следующим шагом\n",
        "    }\n",
        "\n",
        "    // Записываем результат обратно в глобальную память\n",
        "    if (i < n) d_output[i] = temp[tid];\n",
        "}\n",
        "\n",
        "// ФУНКЦИЯ ДЛЯ ИЗМЕРЕНИЯ ВРЕМЕНи\n",
        "void runPerformanceTest(int N) {\n",
        "    cout << \"\\nРазмер массива: \" << N << endl;   // Выводим размер массива\n",
        "\n",
        "    int *h_array = new int[N];                   // Выделяем память для массива на CPU\n",
        "    for (int i = 0; i < N; i++) h_array[i] = 1;  // Заполняем массив единицами\n",
        "\n",
        "    // CPU: РЕДУКЦИЯ\n",
        "    int cpu_sum = 0;                              // Переменная для суммы\n",
        "    auto cpu_start = chrono::high_resolution_clock::now(); // Запуск таймера CPU\n",
        "    for (int i = 0; i < N; i++) cpu_sum += h_array[i];     // Последовательная редукция\n",
        "    auto cpu_end = chrono::high_resolution_clock::now();   // Остановка таймера CPU\n",
        "    chrono::duration<double> cpu_time = cpu_end - cpu_start; // Вычисляем длительность\n",
        "\n",
        "    // GPU: РЕДУКЦИЯ\n",
        "    int *d_input, *d_intermediate;               // Указатели на GPU память\n",
        "    cudaMalloc(&d_input, N * sizeof(int));       // Выделяем память на GPU для входного массива\n",
        "    cudaMemcpy(d_input, h_array, N * sizeof(int), cudaMemcpyHostToDevice); // Копируем данные с CPU на GPU\n",
        "\n",
        "    int threadsPerBlock = 256;                   // Количество потоков в блоке\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock; // Количество блоков в сетке\n",
        "    cudaMalloc(&d_intermediate, blocksPerGrid * sizeof(int)); // Память под промежуточные суммы блоков\n",
        "\n",
        "    cudaEvent_t gpu_start, gpu_stop;             // Таймер GPU\n",
        "    cudaEventCreate(&gpu_start);                 // Создаём событие начала\n",
        "    cudaEventCreate(&gpu_stop);                  // Создаём событие конца\n",
        "    cudaEventRecord(gpu_start);                  // Старт таймера GPU\n",
        "\n",
        "    reductionKernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_intermediate, N);\n",
        "                                                 // Запускаем ядро редукции\n",
        "\n",
        "    int *h_intermediate = new int[blocksPerGrid];\n",
        "    cudaMemcpy(h_intermediate, d_intermediate, blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "                                                 // Копируем промежуточные суммы блоков на CPU\n",
        "\n",
        "    int gpu_sum = 0;\n",
        "    for (int i = 0; i < blocksPerGrid; i++) gpu_sum += h_intermediate[i]; // Финальная редукция сумм блоков на CPU\n",
        "\n",
        "    cudaEventRecord(gpu_stop);                   // Остановка таймера GPU\n",
        "    cudaEventSynchronize(gpu_stop);              // Ждем завершения события\n",
        "    float gpu_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_time, gpu_start, gpu_stop); // Время выполнения GPU редукции\n",
        "\n",
        "    // CPU: СКАНИРОВАНИЕ\n",
        "    int *h_prefix_cpu = new int[N];              // Массив для хранения префиксной суммы CPU\n",
        "    auto cpu_scan_start = chrono::high_resolution_clock::now(); // Старт таймера\n",
        "    h_prefix_cpu[0] = h_array[0];                // Первый элемент префиксной суммы равен первому элементу массива\n",
        "    for (int i = 1; i < N; i++)                  // Последовательное вычисление префиксной суммы\n",
        "        h_prefix_cpu[i] = h_prefix_cpu[i - 1] + h_array[i];\n",
        "    auto cpu_scan_end = chrono::high_resolution_clock::now();   // Остановка таймера\n",
        "    chrono::duration<double> cpu_scan_time = cpu_scan_end - cpu_scan_start; // Время CPU сканирования\n",
        "\n",
        "    // GPU: СКАНИРОВАНИЕ\n",
        "    int *d_output;                               // Память на GPU для результата сканирования\n",
        "    cudaMalloc(&d_output, N * sizeof(int));\n",
        "    cudaEventRecord(gpu_start);                  // Старт таймера\n",
        "    prefixSumKernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, N);\n",
        "                                                 // Запуск ядра сканирования\n",
        "    cudaEventRecord(gpu_stop);                   // Стоп таймера\n",
        "    cudaEventSynchronize(gpu_stop);              // Синхронизация\n",
        "    float gpu_scan_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_scan_time, gpu_start, gpu_stop); // Время выполнения GPU сканирования\n",
        "\n",
        "    // Вывод результатов\n",
        "    cout << \"CPU время (редукция): \" << cpu_time.count() * 1000 << \" мс\" << endl;          // Время CPU редукции\n",
        "    cout << \"GPU время (редукция): \" << gpu_time << \" мс\" << endl;                         // Время GPU редукции\n",
        "    cout << \"CPU время (сканирование): \" << cpu_scan_time.count() * 1000 << \" мс\" << endl; // Время CPU сканирования\n",
        "    cout << \"GPU время (сканирование): \" << gpu_scan_time << \" мс\" << endl;                // Время GPU сканирования\n",
        "\n",
        "    // Освобожденние памяти\n",
        "    delete[] h_array;                             // Освобождаем массив CPU\n",
        "    delete[] h_intermediate;                      // Освобождаем промежуточный массив CPU\n",
        "    delete[] h_prefix_cpu;                        // Освобождаем массив CPU для сканирования\n",
        "    cudaFree(d_input);                            // Освобождаем память GPU\n",
        "    cudaFree(d_intermediate);\n",
        "    cudaFree(d_output);\n",
        "}\n",
        "\n",
        "// Основная функция\n",
        "int main() {\n",
        "    runPerformanceTest(1024);       // Тестируем массив из 1024 элементов\n",
        "    runPerformanceTest(1000000);    // Тестируем массив из 1 000 000 элементов\n",
        "    runPerformanceTest(10000000);   // Тестируем массив из 10 000 000 элементов\n",
        "    return 0;                        // Завершаем программу\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция\n",
        "!nvcc practice73.cu -o practice73 -arch=sm_75 -std=c++11            # -arch=sm_75  - архитектура GPU (Tesla T4 в Colab = sm_75)\n",
        "                                                                    # -std=c++11 — стандарт C++\n",
        "# Запуск\n",
        "!./practice73"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpYIr8tsc1p",
        "outputId": "05d1c5d3-5499-4348-9ece-814c2f10874a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Размер массива: 1024\n",
            "CPU время (редукция): 0.003553 мс\n",
            "GPU время (редукция): 0.153696 мс\n",
            "CPU время (сканирование): 0.004041 мс\n",
            "GPU время (сканирование): 0.028576 мс\n",
            "\n",
            "Размер массива: 1000000\n",
            "CPU время (редукция): 2.88083 мс\n",
            "GPU время (редукция): 0.140608 мс\n",
            "CPU время (сканирование): 5.14558 мс\n",
            "GPU время (сканирование): 0.321344 мс\n",
            "\n",
            "Размер массива: 10000000\n",
            "CPU время (редукция): 27.0933 мс\n",
            "GPU время (редукция): 1.26176 мс\n",
            "CPU время (сканирование): 47.2609 мс\n",
            "GPU время (сканирование): 3.04918 мс\n"
          ]
        }
      ]
    }
  ]
}