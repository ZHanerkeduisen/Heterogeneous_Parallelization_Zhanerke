{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EktUdfCwL12B",
        "outputId": "86c92291-0251-46c1-aeb2-5926ff321e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 30 08:33:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile heap_sort.cu\n",
        "\n",
        "#include <iostream>           // Для cout\n",
        "#include <vector>             // Для std::vector\n",
        "#include <cstdlib>            // Для rand()\n",
        "#include <chrono>             // Для измерения времени\n",
        "#include <cuda_runtime.h>     // Для работы с CUDA API\n",
        "\n",
        "using namespace std;          // Чтобы не писать std::\n",
        "\n",
        "// GPU: функция для «просеивания» (heapify)\n",
        "__device__ void heapify(int* arr, int n, int i) { // Просеивание элемента i в куче размером n\n",
        "    int largest = i;            // Инициализируем наибольший элемент как корень\n",
        "    int l = 2 * i + 1;          // Левый потомок\n",
        "    int r = 2 * i + 2;          // Правый потомок\n",
        "\n",
        "    if (l < n && arr[l] > arr[largest]) largest = l; // Сравнение с левым потомком\n",
        "    if (r < n && arr[r] > arr[largest]) largest = r; // Сравнение с правым потомком\n",
        "\n",
        "    if (largest != i) {         // Если наибольший не корень\n",
        "        int temp = arr[i];      // Меняем местами\n",
        "        arr[i] = arr[largest];\n",
        "        arr[largest] = temp;\n",
        "        heapify(arr, n, largest); // Рекурсивно просеиваем\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel\n",
        "// Построение кучи и извлечение элементов параллельно\n",
        "__global__ void heapSortKernel(int* arr, int n) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x; // Глобальный идентификатор потока\n",
        "\n",
        "    // Построение кучи (heapify) параллельно для разных корней\n",
        "    for (int i = n / 2 - 1 - tid; i >= 0; i -= gridDim.x * blockDim.x) {\n",
        "        heapify(arr, n, i);\n",
        "    }\n",
        "    __syncthreads(); // Синхронизация потоков\n",
        "\n",
        "    // Извлечение элементов из кучи последовательно\n",
        "    // Полное параллельное извлечение сложно реализовать, поэтому делаем здесь CPU-подобное на GPU\n",
        "    if (tid == 0) {\n",
        "        for (int i = n - 1; i >= 0; i--) {\n",
        "            int temp = arr[0];\n",
        "            arr[0] = arr[i];\n",
        "            arr[i] = temp;\n",
        "            heapify(arr, i, 0);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Main\n",
        "int main() {\n",
        "    vector<int> sizes = {10000, 100000};           // Размеры массивов\n",
        "\n",
        "    for (int s = 0; s < sizes.size(); ++s) {\n",
        "        int size = sizes[s];\n",
        "        vector<int> h_arr(size);                   // Массив на CPU\n",
        "\n",
        "        for (int i = 0; i < size; i++) h_arr[i] = rand() % 100000; // Заполняем случайными числами\n",
        "\n",
        "        cout << \"Исходный массив (первые 20 элементов): \";\n",
        "        for (int i = 0; i < 20 && i < size; i++) cout << h_arr[i] << \" \";\n",
        "        cout << endl;\n",
        "\n",
        "        int* d_arr;\n",
        "        cudaMalloc(&d_arr, size * sizeof(int));    // Выделяем память на GPU\n",
        "        cudaMemcpy(d_arr, h_arr.data(), size * sizeof(int), cudaMemcpyHostToDevice); // Копируем массив\n",
        "\n",
        "        int threadsPerBlock = 256;\n",
        "        int numBlocks = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "        auto startTime = chrono::high_resolution_clock::now();\n",
        "\n",
        "        heapSortKernel<<<numBlocks, threadsPerBlock>>>(d_arr, size); // Запуск kernel\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        auto endTime = chrono::high_resolution_clock::now();\n",
        "        cudaMemcpy(h_arr.data(), d_arr, size * sizeof(int), cudaMemcpyDeviceToHost); // Копируем результат\n",
        "\n",
        "        chrono::duration<double> duration = endTime - startTime;\n",
        "\n",
        "        cout << \"Отсортированный массив (первые 20 элементов): \";\n",
        "        for (int i = 0; i < 20 && i < size; i++) cout << h_arr[i] << \" \";\n",
        "        cout << endl;\n",
        "\n",
        "        cout << \"Размер массива: \" << size << endl;\n",
        "        cout << \"Время GPU сортировки: \" << duration.count() << \" секунд\" << endl;\n",
        "\n",
        "        cudaFree(d_arr);\n",
        "\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8PgMPhSL7bX",
        "outputId": "13ea8f15-01af-4aa1-c02b-8fa9cce600be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting heap_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция и запуск в Colab\n",
        "!nvcc heap_sort.cu -o heap_sort\n",
        "!./heap_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt-38lw-MFAx",
        "outputId": "e15ca098-b0dd-4ec7-84ec-d75a9789f508"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный массив (первые 20 элементов): 89383 30886 92777 36915 47793 38335 85386 60492 16649 41421 2362 90027 68690 20059 97763 13926 80540 83426 89172 55736 \n",
            "Отсортированный массив (первые 20 элементов): 89383 30886 92777 36915 47793 38335 85386 60492 16649 41421 2362 90027 68690 20059 97763 13926 80540 83426 89172 55736 \n",
            "Размер массива: 10000\n",
            "Время GPU сортировки: 0.00733036 секунд\n",
            "Исходный массив (первые 20 элементов): 57537 48410 73756 77667 85312 32062 54136 67229 56846 9902 28956 14752 73853 84999 96547 22245 14905 59807 86594 83387 \n",
            "Отсортированный массив (первые 20 элементов): 57537 48410 73756 77667 85312 32062 54136 67229 56846 9902 28956 14752 73853 84999 96547 22245 14905 59807 86594 83387 \n",
            "Размер массива: 100000\n",
            "Время GPU сортировки: 3.7971e-05 секунд\n"
          ]
        }
      ]
    }
  ]
}