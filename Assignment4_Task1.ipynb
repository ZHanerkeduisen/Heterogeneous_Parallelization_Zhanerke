{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtG5nPWMemQI",
        "outputId": "96754b89-51b5-4a71-ca80-a2c83a2962c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing assignment41.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile assignment41.cu\n",
        "// Записываем код  в файл для компиляции CUDA\n",
        "// Assignment 4 Task 1\n",
        "// Вычислить суммы элементов массива с  использованием глобальной памяти\n",
        "// Сравнить результат и время выполнения с  последовательной реализацией на CPU для массива размером 100 000 элементов.\n",
        "\n",
        "#include <iostream>               // Для стандартный ввод-вывод\n",
        "#include <cuda_runtime.h>         // Для CUDA Runtime API\n",
        "#include <chrono>                 // Для измерения времени\n",
        "\n",
        "using namespace std;              // Чтобы не писать std::\n",
        "\n",
        "// CUDA KERNEL\n",
        "__global__ void sumKernel(int *d_array, int *d_result, int n) {                 // Ядро CUDA — выполняется на GPU\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;                            // Глобальный индекс потока\n",
        "    if (idx < n) {                                                              // Каждый поток добавляет один элемент массива в глобальную переменную результата\n",
        "        atomicAdd(d_result, d_array[idx]);                                      // Атомарное сложение в глобальной памяти\n",
        "    }\n",
        "}\n",
        "\n",
        "// Основная функция\n",
        "int main() {\n",
        "    const int N = 100000;               // Размер массива\n",
        "    const int SIZE = N * sizeof(int);   // Размер массива в байтах\n",
        "\n",
        "    int *h_array;                       // Указатель на массив в оперативной памяти (host)\n",
        "    int h_result_cpu = 0;               // Результат суммирования на CPU\n",
        "    int h_result_gpu = 0;               // Результат суммирования на GPU\n",
        "\n",
        "    // Выделяем память на CPU\n",
        "    h_array = new int[N];               // Создаём массив в памяти CPU\n",
        "\n",
        "    // Инициализация массива\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_array[i] = 1;                 // Заполняем единицами (сумма должна быть N)\n",
        "    }                                   // Конец цикла\n",
        "\n",
        "\n",
        "    auto start_cpu = chrono::high_resolution_clock::now(); // Начало замера CPU\n",
        "\n",
        "    for (int i = 0; i < N; i++) {      // Последовательный цикл суммирования\n",
        "        h_result_cpu += h_array[i];    // Прибавляем элемент массива к сумме CPU\n",
        "    }\n",
        "\n",
        "    auto end_cpu = chrono::high_resolution_clock::now();     // Конец замера CPU\n",
        "    chrono::duration<double> cpu_time = end_cpu - start_cpu; // Вычисляем продолжительность времени\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    int *d_array;                              // Массив на GPU\n",
        "    int *d_result;                             // Переменная результата на GPU\n",
        "\n",
        "    cudaMalloc((void**)&d_array, SIZE);        // Выделяем память под массив на GPU\n",
        "    cudaMalloc((void**)&d_result, sizeof(int));// Выделяем память под результат на GPU\n",
        "\n",
        "    cudaMemcpy(d_array, h_array, SIZE, cudaMemcpyHostToDevice); // Копируем массив CPU → GPU\n",
        "    cudaMemset(d_result, 0, sizeof(int));                       // Обнуляем результат на GPU\n",
        "\n",
        "    // Настройка конфигурации запуска\n",
        "    int threadsPerBlock = 256;                                        // Количество потоков в блоке\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;  // Количество блоков, чтобы покрыть весь массив\n",
        "\n",
        "    // Запуск таймера GPU\n",
        "    cudaEvent_t start_gpu, stop_gpu;        // CUDA-события для измерения времени\n",
        "    cudaEventCreate(&start_gpu);            // Инициализация событие старта\n",
        "    cudaEventCreate(&stop_gpu);             // Инициализируем событие конец\n",
        "    cudaEventRecord(start_gpu);             // Старт GPU таймера\n",
        "\n",
        "    //  Запуск CUDA-ядра\n",
        "    sumKernel<<<blocksPerGrid, threadsPerBlock>>>(d_array, d_result, N);\n",
        "\n",
        "\n",
        "    cudaEventRecord(stop_gpu);              // Остановка GPU таймера\n",
        "    cudaEventSynchronize(stop_gpu);         // Ждём завершения\n",
        "\n",
        "    float gpu_time = 0;                     // Переменная для хранения времени GPU\n",
        "    cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu); // Время в миллисекундах\n",
        "\n",
        "    // Копируем результат GPU → CPU\n",
        "    cudaMemcpy(&h_result_gpu, d_result, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Вывод результатов\n",
        "    cout << \"CPU результат: \" << h_result_cpu << endl;\n",
        "    cout << \"GPU результат: \" << h_result_gpu << endl;\n",
        "    cout << \"CPU время: \" << cpu_time.count() * 1000 << \" мс\" << endl;\n",
        "    cout << \"GPU время: \" << gpu_time << \" мс\" << endl;\n",
        "\n",
        "    // Вычисляем ускорение\n",
        "    double speedup = (cpu_time.count() * 1000) / gpu_time;                      // Вычисляем на сколько раз GPU быстрее CPU\n",
        "    cout << \"GPU работает примерно в \" << speedup << \" раз быстрее CPU.\" << endl; // Выводим ускорение\n",
        "\n",
        "    // Освобождение памяти\n",
        "    delete[] h_array;               // Освобождаем память CPU\n",
        "    cudaFree(d_array);              // Освобождаем память GPU массива\n",
        "    cudaFree(d_result);             // Освобождаем память GPU результата\n",
        "\n",
        "    return 0;                       // Завершение программы\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция\n",
        "!nvcc assignment41.cu -o assignment41 -arch=sm_75 -std=c++11            # -arch=sm_75  - архитектура GPU (Tesla T4 в Colab = sm_75)\n",
        "                                                                        # -std=c++11 — стандарт C++\n",
        "# Запуск\n",
        "!./assignment41"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrUSqO4jexl5",
        "outputId": "b708cb33-bf0d-40d4-e02d-2d90d6676b7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU результат: 100000\n",
            "GPU результат: 100000\n",
            "CPU время: 0.279493 мс\n",
            "GPU время: 0.103392 мс\n",
            "GPU работает примерно в 2.70324 раз быстрее CPU.\n"
          ]
        }
      ]
    }
  ]
}