{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqa7RFqVFMZk",
        "outputId": "cde10fc6-291a-4ea0-bef7-73355602ac21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 30 08:06:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4pR1pw5FFkq",
        "outputId": "96ef272a-9191-45bc-cdd2-05fe4fdd8010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting merge_sort.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile merge_sort.cu\n",
        "\n",
        "#include <iostream>           // Для работы с вводом/выводом (cout)\n",
        "#include <vector>             // Для использования динамического массива vector\n",
        "#include <cstdlib>            // Для функции rand()\n",
        "#include <chrono>             // Для измерения времени выполнения\n",
        "#include <cuda_runtime.h>     // Для работы с CUDA API\n",
        "\n",
        "using namespace std;          // Чтобы не писать std:: перед каждым элементом\n",
        "\n",
        "// Функция слияния на GPU\n",
        "__device__ void mergeDevice(int* arr, int left, int mid, int right, int* temp) { // Слияние двух подмассивов на GPU\n",
        "    int i = left;              // Индекс для левой половины\n",
        "    int j = mid;               // Индекс для правой половины\n",
        "    int k = left;              // Индекс для записи в temp\n",
        "\n",
        "    while (i < mid && j < right) { // Пока есть элементы в обеих половинах\n",
        "        if (arr[i] <= arr[j]) temp[k++] = arr[i++]; // Берём элемент из левой половины\n",
        "        else temp[k++] = arr[j++];                 // Берём элемент из правой половины\n",
        "    }\n",
        "\n",
        "    while (i < mid) temp[k++] = arr[i++];         // Копируем оставшиеся элементы левой половины\n",
        "    while (j < right) temp[k++] = arr[j++];       // Копируем оставшиеся элементы правой половины\n",
        "\n",
        "    for (int t = left; t < right; t++) arr[t] = temp[t]; // Переносим результат обратно в arr\n",
        "}\n",
        "\n",
        "// Kernel слияния\n",
        "__global__ void mergeKernel(int* arr, int size, int width, int* temp) { // Kernel GPU\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;   // Глобальный идентификатор потока\n",
        "    int left = tid * 2 * width;                        // Левая граница подмассива\n",
        "    int mid = min(left + width, size);                // Средняя граница\n",
        "    int right = min(left + 2 * width, size);          // Правая граница\n",
        "\n",
        "    if (left < size && mid < size) {                  // Проверяем корректность границ\n",
        "        mergeDevice(arr, left, mid, right, temp);    // Вызываем слияние для данного потока\n",
        "    }\n",
        "}\n",
        "\n",
        "// Main\n",
        "int main() {\n",
        "    const int SIZE = 10000;           // Размер массива\n",
        "    vector<int> h_arr(SIZE);          // Массив на CPU\n",
        "    vector<int> temp(SIZE);           // Временный массив для слияния\n",
        "\n",
        "    for (int i = 0; i < SIZE; i++) h_arr[i] = rand() % 100000; // Заполняем случайными числами\n",
        "\n",
        "    cout << \"Исходный массив (первые 20 элементов): \";\n",
        "    for (int i = 0; i < 20 && i < SIZE; i++) cout << h_arr[i] << \" \"; // Выводим первые 20 элементов\n",
        "    cout << endl;\n",
        "\n",
        "    int* d_arr;\n",
        "    int* d_temp;\n",
        "    cudaMalloc(&d_arr, SIZE * sizeof(int));      // Выделяем память на GPU для массива\n",
        "    cudaMalloc(&d_temp, SIZE * sizeof(int));    // Выделяем память на GPU для временного массива\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr.data(), SIZE * sizeof(int), cudaMemcpyHostToDevice); // Копируем массив на GPU\n",
        "\n",
        "    int threadsPerBlock = 256;                    // Потоки в одном блоке\n",
        "\n",
        "    auto startTime = chrono::high_resolution_clock::now(); // Начало измерения времени\n",
        "\n",
        "    for (int width = 1; width < SIZE; width *= 2) {   // Итеративное увеличение размера подмассива\n",
        "        int numBlocks = (SIZE + 2 * width - 1) / (2 * width); // Количество блоков\n",
        "        mergeKernel<<<numBlocks, threadsPerBlock>>>(d_arr, SIZE, width, d_temp); // Запуск kernel\n",
        "        cudaDeviceSynchronize();                           // Ожидание завершения kernel\n",
        "    }\n",
        "\n",
        "    auto endTime = chrono::high_resolution_clock::now();   // Конец измерения времени\n",
        "    cudaMemcpy(h_arr.data(), d_arr, SIZE * sizeof(int), cudaMemcpyDeviceToHost); // Копируем результат на CPU\n",
        "\n",
        "    chrono::duration<double> duration = endTime - startTime; // Вычисляем время выполнения\n",
        "\n",
        "    cout << \"Отсортированный массив (первые 20 элементов): \";\n",
        "    for (int i = 0; i < 20 && i < SIZE; i++) cout << h_arr[i] << \" \"; // Вывод первых 20 элементов после сортировки\n",
        "    cout << endl;\n",
        "\n",
        "    cout << \"Размер массива: \" << SIZE << endl;\n",
        "    cout << \"Время GPU сортировки: \" << duration.count() << \" секунд\" << endl;\n",
        "\n",
        "    cudaFree(d_arr);   // Освобождаем память GPU\n",
        "    cudaFree(d_temp);\n",
        "\n",
        "    return 0;          // Завершение программы\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция и запуск в Colab\n",
        "!nvcc merge_sort.cu -o merge_sort\n",
        "!./merge_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tINc39ypFzXH",
        "outputId": "0183204b-10e1-4c32-b2c9-9c42c1da6784"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный массив (первые 20 элементов): 89383 30886 92777 36915 47793 38335 85386 60492 16649 41421 2362 90027 68690 20059 97763 13926 80540 83426 89172 55736 \n",
            "Отсортированный массив (первые 20 элементов): 89383 30886 92777 36915 47793 38335 85386 60492 16649 41421 2362 90027 68690 20059 97763 13926 80540 83426 89172 55736 \n",
            "Размер массива: 10000\n",
            "Время GPU сортировки: 0.00771202 секунд\n"
          ]
        }
      ]
    }
  ]
}