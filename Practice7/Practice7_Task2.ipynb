{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yZmIG7-oVPz",
        "outputId": "ec669b1a-f53d-44fb-eeb0-cab7a5bc170b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting practice72.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile practice72.cu\n",
        "\n",
        "// Practice 7 Task 2: Префиксная сумма (сканирование) на GPU\n",
        "// 1. Реализовать алгоритм префиксной суммы (prefix sum) на GPU\n",
        "// 2. Использовать разделяемую память для ускорения\n",
        "// 3. Проверить корректность на тестовых массивах\n",
        "\n",
        "#include <iostream>               // Для стандартного ввода-вывода\n",
        "#include <cuda_runtime.h>         // Для CUDA Runtime API\n",
        "#include <chrono>                 // Для измерения времени\n",
        "\n",
        "using namespace std;              // Чтобы не писать std::\n",
        "\n",
        "// CUDA KERNEL: ПРЕФИКСНАЯ СУММА В БЛОКЕ\n",
        "__global__ void prefixSumKernel(int *d_input, int *d_output, int n) {\n",
        "    extern __shared__ int temp[];                // Разделяемая память блока (shared memory)\n",
        "    int tid = threadIdx.x;                       // Локальный индекс потока внутри блока\n",
        "    int i = blockIdx.x * blockDim.x + tid;      // Глобальный индекс элемента массива\n",
        "\n",
        "    // Загружаем данные из глобальной памяти в shared memory\n",
        "    temp[tid] = (i < n) ? d_input[i] : 0;       // Если поток не выходит за границы массива\n",
        "    __syncthreads();                            // Синхронизация потоков блока перед обработкой\n",
        "\n",
        "    // Шаг вверх (upsweep)\n",
        "    for (int offset = 1; offset < blockDim.x; offset *= 2) {\n",
        "        int index = (tid + 1) * offset * 2 - 1; // Индекс элемента для сложения\n",
        "        if (index < blockDim.x)\n",
        "            temp[index] += temp[index - offset]; // Складываем элементы\n",
        "        __syncthreads();                         // Синхронизация после каждой итерации\n",
        "    }\n",
        "\n",
        "    // Шаг вниз (downsweep)\n",
        "    if (tid == 0)\n",
        "        temp[blockDim.x - 1] = 0;                // Обнуляем последний элемент перед downsweep\n",
        "    __syncthreads();                              // Синхронизация всех потоков\n",
        "\n",
        "    for (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n",
        "        int index = (tid + 1) * offset * 2 - 1;  // Индекс элемента для распределения суммы\n",
        "        if (index < blockDim.x) {\n",
        "            int t = temp[index - offset];        // Сохраняем временное значение\n",
        "            temp[index - offset] = temp[index];  // Перемещаем значение в предыдущую позицию\n",
        "            temp[index] += t;                    // Добавляем сохранённое значение\n",
        "        }\n",
        "        __syncthreads();                         // Синхронизация перед следующей итерацией\n",
        "    }\n",
        "\n",
        "    // Записываем результат обратно в глобальную память\n",
        "    if (i < n)\n",
        "        d_output[i] = temp[tid];\n",
        "}\n",
        "\n",
        "// ФУНКЦИЯ ЗАПУСКА ОДНОГО ТЕСТА\n",
        "void runPrefixSumTest(int N) {\n",
        "    int SIZE = N * sizeof(int);                  // Размер массива в байтах\n",
        "    int *h_array = new int[N];                   // Создаем массив на CPU\n",
        "    int *h_result_cpu = new int[N];              // Массив для результата CPU\n",
        "    int *h_result_gpu = new int[N];              // Массив для результата GPU\n",
        "\n",
        "    // Заполняем массив единицами\n",
        "    for (int i = 0; i < N; i++)\n",
        "        h_array[i] = 1;\n",
        "\n",
        "    // CPU Префиксная сумма\n",
        "    auto cpu_start = chrono::high_resolution_clock::now(); // Запуск таймера CPU\n",
        "    h_result_cpu[0] = h_array[0];                           // Первый элемент равен самому себе\n",
        "    for (int i = 1; i < N; i++)\n",
        "        h_result_cpu[i] = h_result_cpu[i - 1] + h_array[i]; // Каждый следующий элемент = сумма предыдущих\n",
        "    auto cpu_end = chrono::high_resolution_clock::now();   // Остановка таймера CPU\n",
        "    chrono::duration<double> cpu_time = cpu_end - cpu_start; // Вычисляем время выполнения CPU\n",
        "\n",
        "    // GPU Префиксная сумма\n",
        "    int *d_input, *d_output;                              // Указатели на память GPU\n",
        "    cudaMalloc(&d_input, SIZE);                            // Выделяем память на GPU под входной массив\n",
        "    cudaMalloc(&d_output, SIZE);                           // Выделяем память на GPU под результат\n",
        "    cudaMemcpy(d_input, h_array, SIZE, cudaMemcpyHostToDevice); // Копируем данные CPU -> GPU\n",
        "\n",
        "    int threadsPerBlock = 1024;                             // Потоки в одном блоке\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock; // Количество блоков\n",
        "\n",
        "    cudaEvent_t gpu_start, gpu_stop;                       // Объявляем события для таймера GPU\n",
        "    cudaEventCreate(&gpu_start);                           // Создаем событие старта GPU\n",
        "    cudaEventCreate(&gpu_stop);                            // Создаем событие конца GPU\n",
        "    cudaEventRecord(gpu_start);                            // Запуск таймера GPU\n",
        "\n",
        "    prefixSumKernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(d_input, d_output, N); // Запуск ядра GPU\n",
        "\n",
        "    cudaEventRecord(gpu_stop);                             // Остановка таймера GPU\n",
        "    cudaEventSynchronize(gpu_stop);                        // Синхронизация с GPU\n",
        "\n",
        "    float gpu_time = 0;\n",
        "    cudaEventElapsedTime(&gpu_time, gpu_start, gpu_stop);   // Получаем время выполнения GPU\n",
        "\n",
        "    cudaMemcpy(h_result_gpu, d_output, SIZE, cudaMemcpyDeviceToHost); // Копируем результат GPU -> CPU\n",
        "\n",
        "    // Вывод только времени\n",
        "    cout << \"\\n Размер массива: \" << N << endl;            // Вывод размера массива\n",
        "    cout << \"CPU время: \" << cpu_time.count() * 1000 << \" мс\" << endl; // Вывод времени CPU\n",
        "    cout << \"GPU время: \" << gpu_time << \" мс\" << endl;   // Вывод времени GPU\n",
        "\n",
        "    // Освобождение памяти\n",
        "    delete[] h_array;                                      // Освобождаем память CPU\n",
        "    delete[] h_result_cpu;                                 // Освобождаем память CPU\n",
        "    delete[] h_result_gpu;                                 // Освобождаем память CPU\n",
        "    cudaFree(d_input);                                     // Освобождаем память GPU\n",
        "    cudaFree(d_output);                                    // Освобождаем память GPU\n",
        "}\n",
        "\n",
        "// Основная функция\n",
        "int main() {\n",
        "    runPrefixSumTest(1024);        // Тест для массива из 1024 элементов\n",
        "    runPrefixSumTest(1000000);     // Тест для массива из 1 000 000 элементов\n",
        "    runPrefixSumTest(10000000);    // Тест для массива из 10 000 000 элементов\n",
        "    return 0;                      // Завершаем программу\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция\n",
        "!nvcc practice72.cu -o practice72 -arch=sm_75 -std=c++11            # -arch=sm_75  - архитектура GPU (Tesla T4 в Colab = sm_75)\n",
        "                                                                    # -std=c++11 — стандарт C++\n",
        "# Запуск\n",
        "!./practice72"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHk1ITdokcW",
        "outputId": "833598f5-d108-44ce-c4dd-2d0d5c938646"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Размер массива: 1024\n",
            "CPU время: 0.003083 мс\n",
            "GPU время: 0.1416 мс\n",
            "\n",
            " Размер массива: 1000000\n",
            "CPU время: 4.7016 мс\n",
            "GPU время: 0.413888 мс\n",
            "\n",
            " Размер массива: 10000000\n",
            "CPU время: 44.8747 мс\n",
            "GPU время: 3.98112 мс\n"
          ]
        }
      ]
    }
  ]
}
