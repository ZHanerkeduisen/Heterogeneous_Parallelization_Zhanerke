{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sObw7KqMIql",
        "outputId": "cc659715-1af2-4d14-d9e7-130aa98cd09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting practice71.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile practice71.cu\n",
        "\n",
        "// Записываем код  в файл для компиляции CUDA\n",
        "// Practice 7 Task 1\n",
        "// 1. Напишите ядро CUDA для выполнения редукции (суммирования элементов массива).\n",
        "// 2. Используйте разделяемую память для оптимизации доступа к данным.\n",
        "// 3. Проверьте корректность работы на тестовом массиве.\n",
        "\n",
        "\n",
        "#include <iostream>               // Для стандартный ввод-вывод\n",
        "#include <cuda_runtime.h>         // Для CUDA Runtime API\n",
        "#include <chrono>                 // Для измерения времени\n",
        "\n",
        "using namespace std;              // Чтобы не писать std::\n",
        "\n",
        "\n",
        "// CUDA ЯДРО: ПАРАЛЛЕЛЬНАЯ РЕДУКЦИЯ\n",
        "__global__ void reductionKernel(int *d_input, int *d_output, int n) {\n",
        "    extern __shared__ int sdata[];                              // Объявляем разделяемую память внутри блока\n",
        "\n",
        "    unsigned int tid = threadIdx.x;                             // tid — локальный индекс потока внутри блока\n",
        "    unsigned int i = blockIdx.x * blockDim.x + tid;             // i — глобальный индекс элемента массива\n",
        "\n",
        "    if (i < n)                                                  // Проверяем, не вышел ли поток за границы массива\n",
        "        sdata[tid] = d_input[i];                                // Загружаем элемент из глобальной памяти в shared memory\n",
        "    else\n",
        "        sdata[tid] = 0;                                         // Если вышли за границу — записываем 0\n",
        "\n",
        "    __syncthreads();                                            // Синхронизируем все потоки блока перед редукцией\n",
        "\n",
        "    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {     // На каждом шаге уменьшаем активные потоки в 2 раза\n",
        "        if (tid < s)                                            // Работает только первая половина потоков\n",
        "            sdata[tid] += sdata[tid + s];                       // Складываем пару элементов в shared памяти\n",
        "        __syncthreads();                                        // Синхронизация перед следующим шагом\n",
        "    }\n",
        "\n",
        "    if (tid == 0)                                               // Только нулевой поток блока\n",
        "        d_output[blockIdx.x] = sdata[0];                        // Записывает сумму всего блока в глобальную память\n",
        "}\n",
        "\n",
        "// ФУНКЦИЯ ЗАПУСКА ОДНОГО ТЕСТА\n",
        "void runTest(int N) {\n",
        "    cout << \"\\n Размер массива: \" << N  << endl;// Выводим текущий размер тестируемого массива\n",
        "\n",
        "    int SIZE = N * sizeof(int);                                 // Вычисляем размер массива в байтах\n",
        "\n",
        "    int *h_array = new int[N];                                  // Выделяем память под массив в оперативной памяти (CPU)\n",
        "\n",
        "    for (int i = 0; i < N; i++)                                 // Заполняем массив значениями\n",
        "        h_array[i] = 1;                                         // Присваиваем всем элементам значение 1\n",
        "\n",
        "    // ПОСЛЕДОВАТЕЛЬНАЯ РЕДУКЦИЯ НА CPU\n",
        "    int cpu_sum = 0;                                            // Переменная для хранения суммы на CPU\n",
        "\n",
        "    auto cpu_start = chrono::high_resolution_clock::now();     // Запускаем таймер CPU\n",
        "\n",
        "    for (int i = 0; i < N; i++)                                 // Последовательный цикл суммирования\n",
        "        cpu_sum += h_array[i];                                  // Прибавляем каждый элемент массива\n",
        "\n",
        "    auto cpu_end = chrono::high_resolution_clock::now();       // Останавливаем таймер CPU\n",
        "\n",
        "    chrono::duration<double> cpu_time = cpu_end - cpu_start;   // Вычисляем время выполнения CPU\n",
        "\n",
        "    // ПАРАЛЛЕЛЬНАЯ РЕДУКЦИЯ НА GPU\n",
        "    int *d_input, *d_intermediate;                              // Указатели на память GPU\n",
        "\n",
        "    cudaMalloc(&d_input, SIZE);                                 // Выделяем память на GPU под входной массив\n",
        "\n",
        "    cudaMemcpy(d_input, h_array, SIZE, cudaMemcpyHostToDevice);// Копируем данные CPU → GPU\n",
        "\n",
        "    int threadsPerBlock = 256;                                  // Количество потоков в одном блоке\n",
        "\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "                                                                 // Вычисляем количество блоков в сетке\n",
        "\n",
        "    cudaMalloc(&d_intermediate, blocksPerGrid * sizeof(int));  // Память под промежуточные суммы блоков\n",
        "\n",
        "    cudaEvent_t gpu_start, gpu_stop;                            // Объявляем CUDA-события для измерения времени GPU\n",
        "\n",
        "    cudaEventCreate(&gpu_start);                                // Создаём событие старта\n",
        "    cudaEventCreate(&gpu_stop);                                 // Создаём событие окончания\n",
        "\n",
        "    cudaEventRecord(gpu_start);                                 // Запускаем таймер GPU\n",
        "\n",
        "    reductionKernel<<<blocksPerGrid, threadsPerBlock, threadsPerBlock * sizeof(int)>>>(\n",
        "        d_input, d_intermediate, N);                            // Запускаем CUDA-ядро редукции\n",
        "\n",
        "    int *h_intermediate = new int[blocksPerGrid];              // Выделяем массив CPU для хранения сумм блоков\n",
        "\n",
        "    cudaMemcpy(h_intermediate, d_intermediate,\n",
        "               blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "                                                                 // Копируем суммы блоков GPU → CPU\n",
        "\n",
        "    int gpu_sum = 0;                                            // Переменная для итоговой суммы GPU\n",
        "\n",
        "    for (int i = 0; i < blocksPerGrid; i++)                     // Последовательное суммирование сумм блоков\n",
        "        gpu_sum += h_intermediate[i];                           // Финальная редукция на CPU\n",
        "\n",
        "    cudaEventRecord(gpu_stop);                                  // Останавливаем таймер GPU\n",
        "    cudaEventSynchronize(gpu_stop);                             // Дожидаемся завершения события\n",
        "\n",
        "    float gpu_time = 0;                                         // Переменная для хранения времени GPU\n",
        "    cudaEventElapsedTime(&gpu_time, gpu_start, gpu_stop);       // Получаем время выполнения GPU в миллисекундах\n",
        "\n",
        "    // Вывод результатов\n",
        "    cout << \"CPU результат: \" << cpu_sum << endl;                  // Вывод суммы, полученной на CPU\n",
        "    cout << \"GPU результат: \" << gpu_sum << endl;                  // Вывод суммы, полученной на GPU\n",
        "    cout << \"CPU время: \" << cpu_time.count() * 1000 << \" мс\" << endl; // Вывод времени CPU\n",
        "    cout << \"GPU время: \" << gpu_time << \" мс\" << endl;          // Вывод времени GPU\n",
        "\n",
        "    // Освобождение памяти\n",
        "    delete[] h_array;                                           // Освобождаем память CPU массива\n",
        "    delete[] h_intermediate;                                    // Освобождаем промежуточный массив CPU\n",
        "    cudaFree(d_input);                                          // Освобождаем память GPU входного массива\n",
        "    cudaFree(d_intermediate);                                   // Освобождаем память GPU промежуточных сумм\n",
        "}\n",
        "\n",
        "// Основная функция\n",
        "int main() {\n",
        "    runTest(1024);                                              // Тестируем массив из 1024 элементов\n",
        "    runTest(1000000);                                           // Тестируем массив из 1 000 000 элементов\n",
        "    runTest(10000000);                                          // Тестируем массив из 10 000 000 элементов\n",
        "    return 0;                                                   // Завершаем программу\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция\n",
        "!nvcc practice71.cu -o practice71 -arch=sm_75 -std=c++11            # -arch=sm_75  - архитектура GPU (Tesla T4 в Colab = sm_75)\n",
        "                                                                    # -std=c++11 — стандарт C++\n",
        "# Запуск\n",
        "!./practice71\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO5geK-wMZRX",
        "outputId": "7dddd2cc-1114-4952-b30a-38ab34d77008"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Размер массива: 1024\n",
            "CPU результат: 1024\n",
            "GPU результат: 1024\n",
            "CPU время: 0.0027 мс\n",
            "GPU время: 0.10752 мс\n",
            "\n",
            " Размер массива: 1000000\n",
            "CPU результат: 1000000\n",
            "GPU результат: 1000000\n",
            "CPU время: 2.56092 мс\n",
            "GPU время: 0.14976 мс\n",
            "\n",
            " Размер массива: 10000000\n",
            "CPU результат: 10000000\n",
            "GPU результат: 10000000\n",
            "CPU время: 25.9017 мс\n",
            "GPU время: 1.21094 мс\n"
          ]
        }
      ]
    }
  ]
}