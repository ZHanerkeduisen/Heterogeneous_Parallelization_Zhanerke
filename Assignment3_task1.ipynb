{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2kCvphdoZIu",
        "outputId": "c71cd2b5-abb2-4c54-b08d-ea031a5a734d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting assignment31.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile assignment31.cu\n",
        "// Задание 1\n",
        "// Мы умножаем каждый элемент массива на число k\n",
        "// Global memory: каждый поток читает и пишет сразу в глобальную память\n",
        "// Shared memory: поток сначала загружает элемент в разделямую память,  умножает, затем записывает обратно\n",
        "#include <iostream>                      // Для работы с вводом/выводом\n",
        "#include <cuda_runtime.h>                // Основные функции CUDA\n",
        "#include <chrono>                        // Для измерения времени выполнения\n",
        "\n",
        "using namespace std;                     // Чтобы не писать std::\n",
        "\n",
        "// Kernel 1: Только глобальная память\n",
        "__global__ void multiply_global(float *arr, float k, int n)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;   // Глобальный индекс потока\n",
        "\n",
        "    if (idx < n)                                       // Проверка выхода за границы массива\n",
        "    {\n",
        "        arr[idx] = arr[idx] * k;                       // Чтение и запись напрямую в глобальную память\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// Kernel 2: Использование разделяемой памяти\n",
        "__global__ void multiply_shared(float *arr, float k, int n)\n",
        "{\n",
        "    extern __shared__ float shmem[];                   // Объявляем динамическую shared memory\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;   // Глобальный индекс\n",
        "    int tid = threadIdx.x;                             // Локальный индекс внутри блока\n",
        "\n",
        "    if (idx < n)\n",
        "    {\n",
        "        shmem[tid] = arr[idx];                         // Загружаем данные из глобальной памяти в shared memory\n",
        "        __syncthreads();                               // Синхронизация всех потоков блока\n",
        "\n",
        "        shmem[tid] = shmem[tid] * k;                   // Умножаем в быстрой shared memory\n",
        "        __syncthreads();                               // Снова синхронизация\n",
        "\n",
        "        arr[idx] = shmem[tid];                         // Записываем результат обратно в глобальную память\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()                                             // Основная функция\n",
        "{\n",
        "    int n = 1000000;                                   // Размер массива\n",
        "    size_t size = n * sizeof(float);                   // Размер в байтах\n",
        "    float k = 2.5f;                                    // Множитель\n",
        "\n",
        "    // Выделение памяти на CPU\n",
        "    float *h_arr = new float[n];                       // Массив в оперативной памяти\n",
        "\n",
        "    for (int i = 0; i < n; i++)\n",
        "        h_arr[i] = 1.0f;                               // Заполняем начальными значениями\n",
        "\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    float *d_arr;\n",
        "    cudaMalloc(&d_arr, size);                          // Выделяем память в глобальной памяти GPU\n",
        "\n",
        "    cudaMemcpy(d_arr, h_arr, size, cudaMemcpyHostToDevice); // Копируем данные CPU -> GPU\n",
        "\n",
        "    int blockSize = 256;                               // Количество потоков в одном блоке\n",
        "    int gridSize = (n + blockSize - 1) / blockSize;    // Количество блоков в сетке\n",
        "\n",
        "\n",
        "    // Замер времени: глобальная память\n",
        "    cudaDeviceSynchronize();                           // Ожидание завершения всех предыдущих операций\n",
        "    auto start1 = chrono::high_resolution_clock::now();// Начало замера\n",
        "\n",
        "    multiply_global<<<gridSize, blockSize>>>(d_arr, k, n); // Запуск kernel\n",
        "\n",
        "    cudaDeviceSynchronize();                           // Ждем завершения kernel\n",
        "\n",
        "    auto end1 = chrono::high_resolution_clock::now();  // Конец замера\n",
        "\n",
        "    chrono::duration<double> time_global = end1 - start1; // Вычисление продолжительность\n",
        "\n",
        "    // Восстанавливаем исходные данные\n",
        "    cudaMemcpy(d_arr, h_arr, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Замер времени: shared memory\n",
        "    cudaDeviceSynchronize();\n",
        "    auto start2 = chrono::high_resolution_clock::now(); // Начало замера\n",
        "\n",
        "    multiply_shared<<<gridSize, blockSize, blockSize * sizeof(float)>>>(d_arr, k, n);\n",
        "    // Третий параметр задает размер выделяемой shared memory\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end2 = chrono::high_resolution_clock::now(); // Конец замера\n",
        "\n",
        "    chrono::duration<double> time_shared = end2 - start2; // Вычисление продолжительность\n",
        "\n",
        "\n",
        "    // Вывод результатов\n",
        "    cout << \"Время (Global memory): \" << time_global.count() << \" с\" << endl;\n",
        "    cout << \"Время (Shared memory): \" << time_shared.count() << \" с\" << endl;\n",
        "\n",
        "    // Очистка памяти\n",
        "    cudaFree(d_arr);                                   // Освобождаем память GPU\n",
        "    delete[] h_arr;                                    // Освобождаем память CPU\n",
        "\n",
        "    return 0;                                          // Завершения\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция и запуск в Colab\n",
        "!nvcc assignment31.cu -o assignment31\n",
        "!./assignment31\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdz4uYsDoidu",
        "outputId": "af99efbf-4d0e-4bf7-982e-2763cc492f11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время (Global memory): 0.00751199 с\n",
            "Время (Shared memory): 3.271e-06 с\n"
          ]
        }
      ]
    }
  ]
}